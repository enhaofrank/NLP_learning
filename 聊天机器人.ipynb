{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用PaddleNLP生成式API搭建一个聊天机器人\n",
    "\n",
    "近年来，人机对话系统受到了学术界和产业界的广泛关注并取得了不错的发展。开放域对话系统旨在建立一个开放域的多轮对话系统，使得机器可以流畅自然地与人进行语言交互，既可以进行日常问候类的闲聊，又可以完成特定功能，以使得开放域对话系统具有实际应用价值。\n",
    "\n",
    "本实例将重点介绍PaddleNLP内置的**生成式API**的功能和用法，并使用PaddleNLP内置的**plato-mini模型**和配套的**生成式API**实现一个简单的闲聊机器人。\n",
    "\n",
    "## 环境要求\n",
    "\n",
    "* PaddlePaddle\n",
    "\n",
    "   本项目依赖于 PaddlePaddle 2.0 及以上版本，请参考 [安装指南](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html) 进行安装\n",
    "\n",
    "* PaddleNLP \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade paddlenlp -i https://pypi.org/simple\n",
    "   ```\n",
    "* sentencepiece \n",
    "\n",
    "   ```shell\n",
    "   pip install --upgrade sentencepiece -i https://pypi.org/simple\n",
    "   ```\n",
    "\n",
    "* Python\n",
    "\n",
    "    Python的版本要求 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台后续会默认安装PaddleNLP，在此之前可使用如下命令安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/10/ccc761d3e3a994703f31a4d0f93db0d13789d1c624a0cbbe9fe6439ed601/paddlenlp-2.0.5-py3-none-any.whl (435kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 84kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.3)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Found existing installation: paddlenlp 2.0.1\n",
      "    Uninstalling paddlenlp-2.0.1:\n",
      "      Successfully uninstalled paddlenlp-2.0.1\n",
      "Successfully installed paddlenlp-2.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/47/ca/f0d790b6e18b3a6f3bd5e80c2ee4edbb5807286c21cdd0862ca933f751dd/pip-21.1.3-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 17.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.2.3\n",
      "    Uninstalling pip-19.2.3:\n",
      "      Successfully uninstalled pip-19.2.3\n",
      "Successfully installed pip-21.1.3\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.1.85)\n",
      "Collecting sentencepiece\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.85\n",
      "    Uninstalling sentencepiece-0.1.85:\n",
      "      Successfully uninstalled sentencepiece-0.1.85\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\r\n",
    "!pip install --upgrade sentencepiece "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 生成式API\n",
    "\n",
    "**PaddleNLP针对生成式任务提供了`generate()`函数，内嵌于PaddleNLP所有的生成式模型。支持Greedy Search、Beam Search和Sampling解码策略，用户只需指定解码策略以及相应的参数即可完成预测解码，得到生成的sequence的token ids以及概率得分。**\n",
    "\n",
    "下面给大家展示一个GPT模型使用生成API的例子："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 加载 `paddlenlp.transformers.GPTChineseTokenizer`用于数据处理\n",
    "\n",
    "文本数据在输入预训练模型之前，需要经过数据处理转化为Feature。这一过程通常包括分词，token to id，add special token等步骤。  \n",
    "\n",
    "**PaddleNLP对于各种预训练模型已经内置了相应的tokenizer**，指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "调用`GPTChineseTokenizer`的`__call__`方法即可将我们说的话转为模型可接受的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-02 14:35:51,720] [    INFO] - Downloading gpt-cpm-cn-sentencepiece.model from https://paddlenlp.bj.bcebos.com/models/transformers/gpt/gpt-cpm-cn-sentencepiece.model\n",
      "100%|██████████| 697/697 [00:00<00:00, 12392.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTChineseTokenizer\r\n",
    "\r\n",
    "# 设置想要使用模型的名称\r\n",
    "model_name = 'gpt-cpm-small-cn-distill'\r\n",
    "tokenizer = GPTChineseTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.029 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[587, 205, 44, 6110, 1215, 8, 9, 2598, 20779, 255, 6629, 8, 12, 3473, 2475, 8, 2316, 11653, 8, 9]\n",
      "Tensor(shape=[1, 20], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
      "       [[587  , 205  , 44   , 6110 , 1215 , 8    , 9    , 2598 , 20779, 255  , 6629 , 8    , 12   , 3473 , 2475 , 8    , 2316 , 11653, 8    , 9    ]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "user_input = \"花间一壶酒，独酌无相亲。举杯邀明月，\"\r\n",
    "\r\n",
    "# 将文本转为ids\r\n",
    "input_ids = tokenizer(user_input)['input_ids']\r\n",
    "print(input_ids)\r\n",
    "\r\n",
    "# 将转换好的id转为tensor\r\n",
    "input_ids = paddle.to_tensor(input_ids, dtype='int64').unsqueeze(0)\r\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "**PaddleNLP提供了GPT,UnifiedTransformer等中文预训练模型，可以通过预训练模型名称完成一键加载。**\n",
    "\n",
    "GPT以Transformer Decoder的编码器为网络基本组件，采用单向注意力机制，适用于长文本生成任务。\n",
    "\n",
    "PaddleNLP目前提供多种中英文GPT预训练模型，我们这次用的是一个小的中文GPT预训练模型。其他预训练模型请参考[模型列表](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-02 14:36:16,093] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/gpt/gpt-cpm-small-cn-distill.pdparams and saved to /home/aistudio/.paddlenlp/models/gpt-cpm-small-cn-distill\n",
      "[2021-07-02 14:36:16,173] [    INFO] - Downloading gpt-cpm-small-cn-distill.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/gpt/gpt-cpm-small-cn-distill.pdparams\n",
      "100%|██████████| 425342/425342 [00:08<00:00, 48444.20it/s]\n",
      "[2021-07-02 14:36:30,606] [    INFO] - Weights of GPTLMHeadModel not initialized from pretrained model: ['lm_head.decoder_weight']\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTLMHeadModel\r\n",
    "\r\n",
    "# 一键加载中文GPT模型\r\n",
    "model = GPTLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 16], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
      "       [[39  , 8   , 1181, 211 , 8913, 8   , 12  , 8   , 10  , 8   , 10  , 8   , 10  , 8   , 10  , 8   ]])\n",
      "Tensor(shape=[1, 1], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[-0.42379797]])\n"
     ]
    }
   ],
   "source": [
    "# 调用生成API升成文本\r\n",
    "ids, scores = model.generate(\r\n",
    "                input_ids=input_ids,\r\n",
    "                max_length=16,\r\n",
    "                min_length=1,\r\n",
    "                decode_strategy='greedy_search')\r\n",
    "\r\n",
    "print(ids)\r\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对影成三人。    \n"
     ]
    }
   ],
   "source": [
    "generated_ids = ids[0].numpy().tolist()\r\n",
    "\r\n",
    "# 使用tokenizer将生成的id转为文本\r\n",
    "generated_text = tokenizer.convert_ids_to_string(generated_ids)\r\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "可以看到生成的效果还不错，生成式API的用法也是非常的简便。\n",
    "\n",
    "下面我们来展示一下如何使用UnifiedTransformer模型和生成式API完成闲聊对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 加载 `paddlenlp.transformers.UnifiedTransformerTokenizer`用于数据处理\n",
    "\n",
    "`UnifiedTransformerTokenizer`的调用方式与GPT相同，但数据处理的API略有不同。\n",
    "\n",
    "调用`UnifiedTransformerTokenizer`的`dialogue_encode`方法即可将我们说的话转为模型可接受的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-02 14:37:15,579] [    INFO] - Downloading plato-mini-vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini-vocab.txt\n",
      "100%|██████████| 410/410 [00:00<00:00, 5970.81it/s]\n",
      "[2021-07-02 14:37:15,823] [    INFO] - Downloading plato-mini-spm.model from https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini-spm.model\n",
      "100%|██████████| 712/712 [00:00<00:00, 11457.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerTokenizer\r\n",
    "\r\n",
    "# 设置想要使用模型的名称\r\n",
    "model_name = 'plato-mini'\r\n",
    "tokenizer = UnifiedTransformerTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'position_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "user_input = ['你好啊，你今年多大了']\r\n",
    "\r\n",
    "# 调用dialogue_encode方法生成输入\r\n",
    "encoded_input = tokenizer.dialogue_encode(\r\n",
    "                    user_input,\r\n",
    "                    add_start_token_as_response=True,\r\n",
    "                    return_tensors=True,\r\n",
    "                    is_split_into_words=False)\r\n",
    "\r\n",
    "print(encoded_input.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`dialogue_encode`的详细用法，请参考[dialogue_encode](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.unified_transformer.tokenizer.html#paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 使用PaddleNLP一键加载预训练模型\n",
    "\n",
    "与GPT相同，我们可以一键调用UnifiedTransformer预训练模型。\n",
    "\n",
    "[UnifiedTransformer](https://github.com/PaddlePaddle/Knover/tree/luge-dialogue/luge-dialogue)以Transformer的编码器为网络基本组件，采用灵活的注意力机制，十分适合文本生成任务，并在模型输入中加入了标识不同对话技能的special token，使得模型能同时支持闲聊对话、推荐对话和知识对话。\n",
    "\n",
    "PaddleNLP目前为UnifiedTransformer提供了三个中文预训练模型：\n",
    "- `unified_transformer-12L-cn` 该预训练模型是在大规模中文会话数据集上训练得到的\n",
    "- `unified_transformer-12L-cn-luge` 该预训练模型是`unified_transformer-12L-cn`在千言对话数据集上进行微调得到的。\n",
    "- `plato-mini` 该模型使用了十亿级别的中文闲聊对话数据进行预训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-07-02 14:37:48,485] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini.pdparams and saved to /home/aistudio/.paddlenlp/models/plato-mini\n",
      "[2021-07-02 14:37:48,573] [    INFO] - Downloading plato-mini.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/unified_transformer/plato-mini.pdparams\n",
      "100%|██████████| 530157/530157 [00:10<00:00, 50498.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerLMHeadModel\n",
    "\n",
    "model = UnifiedTransformerLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下一步我们将处理好的输入传入generate函数，并配置解码策略。\n",
    "\n",
    "这里我们使用的是TopK加sampling的解码策略。即从概率最大的k个结果中按概率进行采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[20, 15], dtype=int64, place=CPUPlace, stop_gradient=True,\n",
      "       [[6   , 763 , 1164, 7   , 3   , 9   , 42  , 25375, 7   , 28  , 16  , 2   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 2762, 26028, 7   , 28  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 7   , 3   , 9   , 42  , 25375, 7   , 16  , 2   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1991, 7   , 3   , 9   , 94  , 16  , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1585, 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 1585, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 26028, 7   , 3   , 9   , 42  , 25375, 7   , 94  , 2   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1164, 26028, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [912 , 28  , 3   , 6   , 23  , 150 , 1017, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 2762, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 449 , 26028, 7   , 3   , 67  , 16  , 2   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 215 , 1850, 26028, 7   , 3   , 9   , 94  , 16  , 2   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 23  , 215 , 481 , 7   , 3   , 763 , 1017, 26028, 7   , 2   , 0   , 0   , 0   , 0   ],\n",
      "        [9   , 1295, 241 , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [912 , 3   , 6   , 763 , 449 , 25380, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 967 , 26028, 197 , 3   , 763 , 37  , 5201, 7   , 2   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 215 , 1017, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 87  , 120 , 909 , 26028, 3   , 6   , 21  , 25364, 25353, 65  , 115 , 231 , 94  , 2   ],\n",
      "        [6   , 763 , 215 , 4219, 25675, 26028, 7   , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ],\n",
      "        [6   , 763 , 1991, 7   , 3   , 9   , 94  , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ]])\n",
      "Tensor(shape=[20, 1], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[-0.82780552],\n",
      "        [-1.35919023],\n",
      "        [-0.73381782],\n",
      "        [-0.90616119],\n",
      "        [-1.46012509],\n",
      "        [-1.15562165],\n",
      "        [-0.86053336],\n",
      "        [-0.78822470],\n",
      "        [-1.33444166],\n",
      "        [-1.09862638],\n",
      "        [-1.56298566],\n",
      "        [-1.06340051],\n",
      "        [-1.53535044],\n",
      "        [-2.30262637],\n",
      "        [-1.21326554],\n",
      "        [-1.46551800],\n",
      "        [-1.51907444],\n",
      "        [-1.26558709],\n",
      "        [-1.26209486],\n",
      "        [-0.82547915]])\n"
     ]
    }
   ],
   "source": [
    "ids, scores = model.generate(\n",
    "                input_ids=encoded_input['input_ids'],\n",
    "                token_type_ids=encoded_input['token_type_ids'],\n",
    "                position_ids=encoded_input['position_ids'],\n",
    "                attention_mask=encoded_input['attention_mask'],\n",
    "                max_length=64,\n",
    "                min_length=1,\n",
    "                decode_strategy='sampling',\n",
    "                top_k=5,\n",
    "                num_return_sequences=20)\n",
    "\n",
    "print(ids)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我今年23了,你多大了?']\n"
     ]
    }
   ],
   "source": [
    "from utils import select_response\r\n",
    "\r\n",
    "# 简单根据概率选取最佳回复\r\n",
    "result = select_response(ids, scores, tokenizer, keep_space=False, num_return_sequences=20)\r\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "关于生成式API更详细的用法，请参考[generate](https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.generation_utils.html#paddlenlp.transformers.generation_utils.GenerationMixin.generate)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 下面我们去终端里试试多轮对话吧！\n",
    "\n",
    "PaddleNLP的example中提供了搭建完整对话系统的代码（[人机交互](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/dialogue/unified_transformer#%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92)）。我们可以去终端里尝试一下。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
