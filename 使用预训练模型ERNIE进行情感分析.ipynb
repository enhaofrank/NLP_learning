{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用PaddleNLP语义预训练模型ERNIE优化情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "近年来随着深度学习的发展，模型参数数量飞速增长，为了训练这些参数，需要更大的数据集来避免过拟合。然而，对于大部分NLP任务来说，构建大规模的标注数据集成本过高，非常困难，特别是对于句法和语义相关的任务。相比之下，大规模的未标注语料库的构建则相对容易。最近的研究表明，基于大规模未标注语料库的预训练模型（Pretrained Models, PTM) 能够习得通用的语言表示，将预训练模型Fine-tune到下游任务，能够获得出色的表现。另外，预训练模型能够避免从零开始训练模型。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/327f44ff3ed24493adca5ddc4dc24bf61eebe67c84a6492f872406f464fde91e\" width=\"60%\" height=\"50%\"> <br />\n",
    "</p>\n",
    "<br><center>图2：预训练模型一览，图片来源：https://github.com/thunlp/PLMpapers</center></br>\n",
    "                                                                                                                        \n",
    "本示例展示了以ERNIE([Enhanced Representation through Knowledge Integration](https://arxiv.org/pdf/1904.09223))为代表的预训练模型如何Finetune完成中文情感分析任务。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "安装PaddleNLP，在此之前可使用如下命令安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e1/f071c0952ffffff18e821b5f3d47a534aadd0ba83e8a8ced4dfdb5534874/paddlenlp-2.0.4-py3-none-any.whl (435kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 74kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Collecting multiprocess (from paddlenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/d8/d7bbcef5c03890f5fe983d8419b0c5236af3657c5aa9bddf1991a6ed813a/multiprocess-0.70.12.2-py37-none-any.whl (112kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 13kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Collecting dill>=0.3.4 (from multiprocess->paddlenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 45kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: dill, multiprocess, paddlenlp\n",
      "  Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "  Found existing installation: paddlenlp 2.0.0rc7\n",
      "    Uninstalling paddlenlp-2.0.0rc7:\n",
      "      Successfully uninstalled paddlenlp-2.0.0rc7\n",
      "Successfully installed dill-0.3.4 multiprocess-0.70.12.2 paddlenlp-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 加载数据集\n",
    "\n",
    "以公开中文情感分析数据集ChnSenticorp为例。PaddleNLP已经内置该数据集，一键即可加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "2021-06-27 11:02:06,715 - INFO - unique_endpoints {''}\n",
      "2021-06-27 11:02:06,716 - INFO - unique_endpoints {''}\n",
      "2021-06-27 11:02:06,718 - INFO - Downloading ChnSentiCorp.zip from https://dataset-bj.cdn.bcebos.com/qianyan/ChnSentiCorp.zip\n",
      "100%|██████████| 1909/1909 [00:00<00:00, 50949.88it/s]\n",
      "2021-06-27 11:02:06,869 - INFO - File /home/aistudio/.paddlenlp/datasets/ChnSentiCorp/ChnSentiCorp.zip md5 checking...\n",
      "2021-06-27 11:02:06,875 - INFO - Decompressing /home/aistudio/.paddlenlp/datasets/ChnSentiCorp/ChnSentiCorp.zip...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n",
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1, 'qid': ''}\n",
      "{'text': '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'label': 1, 'qid': ''}\n",
      "{'text': '房间太小。其他的都一般。。。。。。。。。', 'label': 0, 'qid': ''}\n",
      "{'text': '1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.', 'label': 0, 'qid': ''}\n",
      "{'text': '今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。', 'label': 1, 'qid': ''}\n"
     ]
    }
   ],
   "source": [
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "train_ds, dev_ds, test_ds = load_dataset(\n",
    "    \"chnsenticorp\", splits=[\"train\", \"dev\", \"test\"])\n",
    "\n",
    "print(train_ds.label_list)\n",
    "\n",
    "for data in train_ds.data[:5]:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "每条数据包含一句评论和对应的标签，0或1。0代表负向评论，1代表正向评论。\n",
    "\n",
    "之后，还需要对输入句子进行数据处理，如切词，映射词表id等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PaddleNLP一键加载预训练模型\n",
    "\n",
    "\n",
    "情感分析本质是一个文本分类任务，PaddleNLP对于各种预训练模型已经内置了对于下游任务-文本分类的Fine-tune网络。以下教程ERNIE为例，介绍如何将预训练模型Fine-tune完成文本分类任务。\n",
    "\n",
    "### `paddlenlp.transformers.ErnieModel()`一行代码即可加载预训练模型ERNIE。\n",
    "\n",
    "### `paddlenlp.transformers.ErnieForSequenceClassification()`一行代码即可加载预训练模型ERNIE用于文本分类任务的Fine-tune网络。\n",
    "其在ERNIE模型后拼接上一个全连接网络（Full Connected）进行分类。\n",
    "\n",
    "### `paddlenlp.transformers.ErnieForSequenceClassification.from_pretrained()` 只需指定想要使用的模型名称和文本分类的类别数即可完成网络定义。\n",
    "\n",
    "PaddleNLP不仅支持ERNIE预训练模型，还支持BERT、RoBERTa、Electra等预训练模型，可跳转到文末了解更多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-27 11:03:42,853] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "[2021-06-27 11:03:43,853] [    INFO] - Weights from pretrained model not used in ErnieModel: ['cls.predictions.layer_norm.weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.bias', 'cls.predictions.transform.weight', 'cls.predictions.layer_norm.bias']\n",
      "[2021-06-27 11:03:44,144] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n"
     ]
    }
   ],
   "source": [
    "# 设置想要使用模型的名称\n",
    "MODEL_NAME = \"ernie-1.0\"\n",
    "\n",
    "ernie_model = ppnlp.transformers.ErnieModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=len(train_ds.label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 调用`ppnlp.transformers.ErnieTokenizer`进行数据处理\n",
    "\n",
    "预训练模型ERNIE对中文数据的处理是以字为单位。PaddleNLP对于各种预训练模型已经内置了相应的tokenizer。指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "tokenizer作用为将原始输入文本转化成模型model可以接受的输入数据形式。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ernie_network_1.png\" hspace='10'/> <br />\n",
    "</p>\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ernie_network_2.png\" hspace='10'/> <br />\n",
    "</p>\n",
    "<br><center>图3：ERNIE模型框架示意图</center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-27 11:09:16,000] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt\n",
      "100%|██████████| 90/90 [00:00<00:00, 3848.89it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['请', '输', '入', '测', '试', '样', '例']\n",
      "Tokens id: [647, 789, 109, 558, 525, 314, 656]\n",
      "Tokens : Tensor(shape=[1, 9], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[1  , 647, 789, 109, 558, 525, 314, 656, 2  ]])\n",
      "Token wise output: [1, 9, 768], Pooled output: [1, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "# 将原始输入文本切分token，\n",
    "tokens = tokenizer._tokenize(\"请输入测试样例\")\n",
    "print(\"Tokens: {}\".format(tokens))\n",
    "\n",
    "# token映射为对应token id\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"Tokens id: {}\".format(tokens_ids))\n",
    "\n",
    "\n",
    "# 拼接上预训练模型对应的特殊token ，如[CLS]、[SEP]\n",
    "tokens_ids = tokenizer.build_inputs_with_special_tokens(tokens_ids)\n",
    "\n",
    "# 转化成paddle框架数据格式\n",
    "tokens_pd = paddle.to_tensor([tokens_ids])\n",
    "print(\"Tokens : {}\".format(tokens_pd))\n",
    "\n",
    "# 此时即可输入ERNIE模型中得到相应输出\n",
    "sequence_output, pooled_output = ernie_model(tokens_pd)\n",
    "print(\"Token wise output: {}, Pooled output: {}\".format(sequence_output.shape, pooled_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "从以上代码可以看出，ERNIE模型输出有2个tensor。\n",
    "\n",
    "* `sequence_output`是对应每个输入token的语义特征表示，shape为(1, num_tokens, hidden_size)。其一般用于序列标注、问答等任务。\n",
    "* `pooled_output`是对应整个句子的语义特征表示，shape为(1, hidden_size)。其一般用于文本分类、信息检索等任务。\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "如需使用ernie-tiny预训练模型，则对应的tokenizer应该使用`paddlenlp.transformers.ErnieTinyTokenizer.from_pretrained('ernie-tiny')`\n",
    "\n",
    "以上代码示例展示了使用Transformer类预训练模型所需的数据处理步骤。为了更方便地使用，PaddleNLP同时提供了更加高阶API，一键即可返回模型所需数据格式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "\t[1, 647, 789, 109, 558, 525, 314, 656, 2]\n",
      "token_type_ids:\n",
      "\t[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "input_ids : Tensor(shape=[1, 9], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[1  , 647, 789, 109, 558, 525, 314, 656, 2  ]])\n",
      "token_type_ids : Tensor(shape=[1, 9], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Token wise output: [1, 9, 768], Pooled output: [1, 768]\n"
     ]
    }
   ],
   "source": [
    "# 一行代码完成切分token，映射token ID以及拼接特殊token\n",
    "encoded_text = tokenizer(text=\"请输入测试样例\")\n",
    "for key, value in encoded_text.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))\n",
    "\n",
    "# 转化成paddle框架数据格式\n",
    "input_ids = paddle.to_tensor([encoded_text['input_ids']])\n",
    "print(\"input_ids : {}\".format(input_ids))\n",
    "segment_ids = paddle.to_tensor([encoded_text['token_type_ids']])\n",
    "print(\"token_type_ids : {}\".format(segment_ids))\n",
    "\n",
    "# 此时即可输入ERNIE模型中得到相应输出\n",
    "sequence_output, pooled_output = ernie_model(input_ids, segment_ids)\n",
    "print(\"Token wise output: {}, Pooled output: {}\".format(sequence_output.shape, pooled_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "由以上代码可以见，tokenizer提供了一种非常便利的方式生成模型所需的数据格式。\n",
    "\n",
    "以上，\n",
    "* `input_ids`: 表示输入文本的token ID。\n",
    "* `segment_ids`: 表示对应的token属于输入的第一个句子还是第二个句子。（Transformer类预训练模型支持单句以及句对输入。）详细参见左侧utils.py文件中`convert_example()`函数解释。\n",
    "* `seq_len`： 表示输入句子的token个数。\n",
    "* `input_mask`：表示对应的token是否一个padding token。由于一个batch中的输入句子长度不同，所以需要将不同长度的句子padding到统一固定长度。1表示真实输入，0表示对应token为padding token。\n",
    "* `position_ids`: 表示对应token在整个输入序列中的位置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/data/vocab.py:220: UserWarning: The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \n",
      "  \"The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单句输入token (str): ['[CLS]', '请', '输', '入', '测', '试', '样', '例', '[SEP]']\n",
      "单句输入token (int): [1, 647, 789, 109, 558, 525, 314, 656, 2]\n",
      "单句输入segment ids : [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "句对输入token (str): ['[CLS]', '请', '输', '入', '测', '试', '样', '例', '1', '[SEP]', '请', '输', '入', '测', '试', '样', '例', '2', '[SEP]']\n",
      "句对输入token (int): [1, 647, 789, 109, 558, 525, 314, 656, 208, 2, 647, 789, 109, 558, 525, 314, 656, 249, 2]\n",
      "句对输入segment ids : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 单句输入\n",
    "single_seg_input = tokenizer(text=\"请输入测试样例\")\n",
    "# 句对输入\n",
    "multi_seg_input = tokenizer(text=\"请输入测试样例1\", text_pair=\"请输入测试样例2\")\n",
    "\n",
    "print(\"单句输入token (str): {}\".format(tokenizer.convert_ids_to_tokens(single_seg_input['input_ids'])))\n",
    "print(\"单句输入token (int): {}\".format(single_seg_input['input_ids']))\n",
    "print(\"单句输入segment ids : {}\".format(single_seg_input['token_type_ids']))\n",
    "\n",
    "print()\n",
    "print(\"句对输入token (str): {}\".format(tokenizer.convert_ids_to_tokens(multi_seg_input['input_ids'])))\n",
    "print(\"句对输入token (int): {}\".format(multi_seg_input['input_ids']))\n",
    "print(\"句对输入segment ids : {}\".format(multi_seg_input['token_type_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "\t[1, 647, 789, 109, 558, 525, 314, 656, 2]\n",
      "token_type_ids:\n",
      "\t[0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Highlight: padding到统一长度\n",
    "encoded_text = tokenizer(text=\"请输入测试样例\",  max_seq_len=15)\n",
    "\n",
    "for key, value in encoded_text.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**以上代码示例详细介绍了tokenizer的用法。**\n",
    "\n",
    "**接下来使用tokenzier处理ChnSentiCorp数据集。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据读入\n",
    "\n",
    "使用`paddle.io.DataLoader`接口多线程异步加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from utils import  convert_example, create_dataloader\n",
    "\n",
    "# 模型运行批处理大小\n",
    "batch_size = 32\n",
    "max_seq_length = 128\n",
    "\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length)\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "    Stack(dtype=\"int64\")  # label\n",
    "): [data for data in fn(samples)]\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)\n",
    "dev_data_loader = create_dataloader(\n",
    "    dev_ds,\n",
    "    mode='dev',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 设置Fine-Tune优化策略，接入评价指标\n",
    "适用于ERNIE/BERT这类Transformer模型的学习率为warmup的动态学习率。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2bc624280a614a80b5449773192be460f195b13af89e4e5cbaf62bf6ac16de2c\" width=\"40%\" height=\"30%\"/> <br />\n",
    "</p>\n",
    "<br><center>图4：动态学习率示意图</center></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "# 训练过程中的最大学习率\n",
    "learning_rate = 5e-5 \n",
    "# 训练轮次\n",
    "epochs = 1 #3\n",
    "# 学习率预热比例\n",
    "warmup_proportion = 0.1\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\n",
    "weight_decay = 0.01\n",
    "\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ])\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估\n",
    "\n",
    "模型训练的过程通常有以下步骤：\n",
    "\n",
    "1. 从dataloader中取出一个batch data\n",
    "2. 将batch data喂给model，做前向计算\n",
    "3. 将前向计算结果传给损失函数，计算loss。将前向计算结果传给评价方法，计算评价指标。\n",
    "4. loss反向回传，更新梯度。重复以上步骤。\n",
    "\n",
    "每训练一个epoch时，程序将会评估一次，评估当前模型训练的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checkpoint文件夹用于保存训练模型\n",
    "!mkdir /home/aistudio/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.18833, acc: 0.95625\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.09999, acc: 0.95469\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.08534, acc: 0.94896\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.25348, acc: 0.94531\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.08655, acc: 0.94937\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.21048, acc: 0.95208\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.06947, acc: 0.95179\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.16921, acc: 0.95039\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.18509, acc: 0.94931\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.15490, acc: 0.95156\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.21453, acc: 0.95227\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.09742, acc: 0.95391\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.16147, acc: 0.95312\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.27064, acc: 0.95223\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.14671, acc: 0.95292\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.03644, acc: 0.95391\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.31886, acc: 0.95423\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.11128, acc: 0.95365\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.07882, acc: 0.95444\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.14324, acc: 0.95422\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.27616, acc: 0.95446\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.14092, acc: 0.95355\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.20979, acc: 0.95340\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.14164, acc: 0.95273\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.21733, acc: 0.95275\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.25874, acc: 0.95252\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.12483, acc: 0.95289\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.37468, acc: 0.95234\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.16767, acc: 0.95205\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.16033, acc: 0.95208\n",
      "eval loss: 0.19372, accu: 0.93000\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "from utils import evaluate\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, segment_ids, labels = batch\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0 :\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "    evaluate(model, criterion, metric, dev_data_loader)\n",
    "\n",
    "model.save_pretrained('/home/aistudio/checkpoint')\n",
    "#tokenizer.save_pretrained('/home/aistudio/checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型预测\n",
    "\n",
    "训练保存好的训练，即可用于预测。如以下示例代码自定义预测数据，调用`predict()`函数即可一键预测。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {'text': '这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'} \t Lable: negative\n",
      "Data: {'text': '怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片'} \t Lable: negative\n",
      "Data: {'text': '作为老的四星酒店，房间依然很整洁，相当不错。机场接机服务很好，可以在车上办理入住手续，节省时间。'} \t Lable: positive\n"
     ]
    }
   ],
   "source": [
    "from utils import predict\n",
    "\n",
    "data = [\n",
    "    {\"text\":'这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'},\n",
    "    {\"text\":'怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片'},\n",
    "    {\"text\":'作为老的四星酒店，房间依然很整洁，相当不错。机场接机服务很好，可以在车上办理入住手续，节省时间。'},\n",
    "]\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "results = predict(\n",
    "    model, data, tokenizer, label_map, batch_size=batch_size)\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
